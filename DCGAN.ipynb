{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6511b36-c7dd-4fbc-85c2-964962bbfccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
    "\n",
    "import keras\n",
    "from keras import datasets, layers, models, ops\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7887c57f-709e-45ac-9864-007f787f5908",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNetBlock(layers.Layer):\n",
    "    def __init__(self, filters, kernel_size, activation=\"linear\", **kwargs):\n",
    "        super(ResNetBlock, self).__init__(**kwargs)\n",
    "        self.filters = filters\n",
    "        self.kernel_size = kernel_size\n",
    "        self.activation = activation\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.conv1 = layers.Conv2D(self.filters, self.kernel_size, padding='same')\n",
    "        self.bn = layers.BatchNormalization()\n",
    "        self.act = layers.Activation(activation=self.activation)\n",
    "        self.conv2 = layers.Conv2D(self.filters, self.kernel_size, padding='same')\n",
    "        self.bn2 = layers.BatchNormalization()\n",
    "\n",
    "\n",
    "    def call(self, x):\n",
    "        y = self.conv1(x)\n",
    "        y = self.bn(y)\n",
    "        y = self.act(y)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "\n",
    "        return x + y\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(ResNetBlock, self).get_config()\n",
    "        config.update(\n",
    "            {\n",
    "            \"filters\": self.filters,\n",
    "            \"kernel_size\": self.kernel_size,\n",
    "            \"activation\": self.activation\n",
    "        }\n",
    "        )\n",
    "        \n",
    "        return config\n",
    "\n",
    "\n",
    "class UpBlock(layers.Layer):\n",
    "    def __init__(self, filters, kernel_size, activation=\"linear\", depth=2, **kwargs):\n",
    "        super(UpBlock, self).__init__(**kwargs)\n",
    "        self.filters = filters\n",
    "        self.kernel_size = kernel_size\n",
    "        self.activation = activation\n",
    "        self.depth = depth\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.resnet_layers = []\n",
    "        self.UpSampling = layers.UpSampling2D(size=(2, 2))\n",
    "\n",
    "        self.first_resnet = ResNetBlock(self.filters, self.kernel_size, self.activation)\n",
    "\n",
    "        if self.depth > 1:\n",
    "            for _ in range(self.depth-1):\n",
    "                layer_i = ResNetBlock(self.filters, self.kernel_size, self.activation)\n",
    "                self.resnet_layers.append(layer_i)\n",
    "\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.first_resnet(x)\n",
    "        x = self.UpSampling(x)\n",
    "        for layer in self.resnet_layers:\n",
    "            x = layer(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(UpBlock, self).get_config()\n",
    "        config.update(\n",
    "            {\n",
    "            \"filters\": self.filters,\n",
    "            \"kernel_size\": self.kernel_size,\n",
    "            \"activation\": self.activation,\n",
    "            \"depth\": self.depth\n",
    "        }\n",
    "        )\n",
    "        \n",
    "        return config\n",
    "\n",
    "\n",
    "class DownBlock(layers.Layer):\n",
    "    def __init__(self, filters, kernel_size, activation=\"linear\", depth=2, dropout=.1, **kwargs):\n",
    "        super(DownBlock, self).__init__(**kwargs)\n",
    "        self.filters = filters\n",
    "        self.kernel_size = kernel_size\n",
    "        self.activation = activation\n",
    "        self.depth = depth\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.resnet_layers = []\n",
    "        self.pooling = layers.MaxPooling2D()\n",
    "\n",
    "\n",
    "        for _ in range(self.depth):\n",
    "            layer_i = ResNetBlock(self.filters, self.kernel_size, self.activation)\n",
    "            self.resnet_layers.append(layer_i)\n",
    "\n",
    "        self.dropout = layers.Dropout(self.dropout)\n",
    "\n",
    "\n",
    "    def call(self, x):\n",
    "        for layer in self.resnet_layers:\n",
    "            x = layer(x)\n",
    "\n",
    "        x = self.pooling(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(DownBlock, self).get_config()\n",
    "        \n",
    "        config.update(\n",
    "            {\n",
    "            \"filters\": self.filters,\n",
    "            \"kernel_size\": self.kernel_size,\n",
    "            \"activation\": self.activation,\n",
    "            \"depth\": self.depth,\n",
    "            \"dropout\": self.dropout\n",
    "        }\n",
    "        )\n",
    "        \n",
    "        return config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8442bfb-c9b2-4554-9d55-1fc831d992cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_config = {\n",
    "    \"latent_dim\": 256,\n",
    "    \"start_res\": 4,\n",
    "    \"channels\": [512, 512, 256, 128, 64, 32],\n",
    "    \"image_channels\": 3,\n",
    "    \"kernel_size\": 4,\n",
    "    \"activation\": \"swish\",\n",
    "    \"depth\": 2,\n",
    "}\n",
    "\n",
    "discriminator_config = {\n",
    "    \"image_size\": 128,\n",
    "    \"image_channels\": 3,\n",
    "    \"channels\": [64, 128, 256, 512],\n",
    "    \"kernel_size\": 3,\n",
    "    \"activation\": \"gelu\",\n",
    "    \"depth\": 1,\n",
    "    \"dropout\": .1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58d6954-9de6-412a-b0d2-0d8a0f637ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "@keras.saving.register_keras_serializable()\n",
    "class Generator(keras.Model):\n",
    "    def __init__(self, latent_dim, start_res, channels, image_channels, kernel_size, activation, depth, **kwargs):\n",
    "        super(Generator, self).__init__(**kwargs)\n",
    "        self.latent_dim = latent_dim\n",
    "        self.start_res = start_res\n",
    "        self.channels = channels\n",
    "        self.image_channels = image_channels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.activation = activation\n",
    "        self.depth = depth\n",
    "\n",
    "\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.ff = layers.Dense(self.start_res*self.start_res*self.channels[0])\n",
    "        self.bn = layers.BatchNormalization()\n",
    "        self.activation = layers.Activation(activation=self.activation)\n",
    "        self.reshape = layers.Reshape((self.start_res, self.start_res, self.channels[0]))\n",
    "\n",
    "        self.upblocks = []\n",
    "\n",
    "        for filters in self.channels[1:]:\n",
    "            layer_i = UpBlock(filters, self.kernel_size, self.activation, self.depth)\n",
    "            self.upblocks.append(layer_i)\n",
    "\n",
    "        self.outputs = layers.Conv2D(self.image_channels, kernel_size=self.kernel_size, padding='same')\n",
    "\n",
    "    \n",
    "    def call(self, x):\n",
    "        x = self.ff(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.reshape(x)\n",
    "        for upblock in self.upblocks:\n",
    "            x = upblock(x)\n",
    "\n",
    "        x = self.outputs(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(Generator, self).get_config()\n",
    "\n",
    "        config.update(\n",
    "            {\n",
    "            \"latent_dim\": self.latent_dim,\n",
    "            \"start_res\": self.start_res,\n",
    "            \"channels\": self.channels,\n",
    "            \"image_channels\": self.image_channels,\n",
    "            \"kernel_size\": self.kernel_size,\n",
    "            \"activation\": self.activation,\n",
    "            \"depth\": self.depth\n",
    "            }\n",
    "        )\n",
    "\n",
    "        return config\n",
    "\n",
    "@keras.saving.register_keras_serializable()\n",
    "class Discriminator(keras.Model):\n",
    "    def __init__(self, image_size, image_channels, channels, kernel_size, activation, depth, dropout, **kwargs):\n",
    "        super(Discriminator, self).__init__(**kwargs)\n",
    "        self.image_size = image_size\n",
    "        self.image_channels = image_channels\n",
    "        self.channels = channels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.activation = activation\n",
    "        self.depth = depth\n",
    "        self.dropout = dropout\n",
    "\n",
    "\n",
    "\n",
    "    def build(self, input_shape):\n",
    "\n",
    "        self.downblocks = []\n",
    "\n",
    "        for filters in self.channels:\n",
    "            layer_i = DownBlock(filters, self.kernel_size, self.activation, self.depth, self.dropout)\n",
    "            self.downblocks.append(layer_i)\n",
    "\n",
    "        self.flatten = layers.Flatten()\n",
    "        self.outputs = layers.Dense(1, activation='sigmoid')\n",
    "    \n",
    "    def call(self, x):\n",
    "        \n",
    "        for downblock in self.downblocks:\n",
    "            x = downblock(x)\n",
    "\n",
    "        x = self.flatten(x)\n",
    "\n",
    "        x = self.outputs(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def get_config(self):\n",
    "        # Include hyperparameters in the model configuration\n",
    "        config = super(Discriminator, self).get_config()\n",
    "        \n",
    "        config.update(\n",
    "            {\n",
    "            \"image_size\": self.image_size,\n",
    "            \"image_channels\": self.image_channels,\n",
    "            \"channels\": self.channels,\n",
    "            \"kernel_size\": self.kernel_size,\n",
    "            \"activation\": self.activation,\n",
    "            \"depth\": self.depth,\n",
    "            \"dropout\": self.dropout\n",
    "        }\n",
    "        )\n",
    "        \n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8983ec8f-0a9a-48bb-9629-d6dfe28e54e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = Generator(**generator_config)\n",
    "discriminator = Discriminator(**discriminator_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae8c8b7-37a5-4753-8ca3-9e72005cc6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GenerativeAdversarialNetwork(keras.Model):\n",
    "    def __init__(self, generator, discriminator, latent_dim, **kwargs):\n",
    "        super(GenerativeAdversarialNetwork, self).__init__(**kwargs)\n",
    "        self.generator = generator\n",
    "        self.discriminator = discriminator\n",
    "        self.latent_dim = latent_dim\n",
    "        self.seed_generator = keras.random.SeedGenerator(1337)\n",
    "        self.train_prog_noise = tf.random.normal(shape=(25, latent_dim), seed=42)\n",
    "        \n",
    "    def compile(self, d_optimizer, g_optimizer, loss_fn):\n",
    "        super().compile()\n",
    "        self.d_optimizer = d_optimizer\n",
    "        self.g_optimizer = g_optimizer\n",
    "        self.loss_fn = loss_fn\n",
    "        self.d_loss_metric = keras.metrics.Mean(name=\"d_loss\")\n",
    "        self.g_loss_metric = keras.metrics.Mean(name=\"g_loss\")\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [self.d_loss_metric, self.g_loss_metric]\n",
    "\n",
    "    def train_step(self, real_images):\n",
    "        # Sample random points in the latent space\n",
    "        batch_size = ops.shape(real_images)[0]\n",
    "        random_latent_vectors = keras.random.normal(\n",
    "            shape=(batch_size, self.latent_dim), seed=self.seed_generator\n",
    "        )\n",
    "\n",
    "        generated_images = self.generator(random_latent_vectors)\n",
    "\n",
    "        combined_images = ops.concatenate([generated_images, real_images], axis=0)\n",
    "\n",
    "        labels = ops.concatenate(\n",
    "            [ops.ones((batch_size, 1)), ops.zeros((batch_size, 1))], axis=0\n",
    "        )\n",
    "        labels += 0.05 * tf.random.uniform(tf.shape(labels))\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self.discriminator(combined_images)\n",
    "            d_loss = self.loss_fn(labels, predictions)\n",
    "        grads = tape.gradient(d_loss, self.discriminator.trainable_weights)\n",
    "        self.d_optimizer.apply_gradients(\n",
    "            zip(grads, self.discriminator.trainable_weights)\n",
    "        )\n",
    "\n",
    "        random_latent_vectors = keras.random.normal(\n",
    "            shape=(batch_size, self.latent_dim), seed=self.seed_generator\n",
    "        )\n",
    "\n",
    "        misleading_labels = ops.zeros((batch_size, 1))\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self.discriminator(self.generator(random_latent_vectors))\n",
    "            g_loss = self.loss_fn(misleading_labels, predictions)\n",
    "        grads = tape.gradient(g_loss, self.generator.trainable_weights)\n",
    "        self.g_optimizer.apply_gradients(zip(grads, self.generator.trainable_weights))\n",
    "\n",
    "        self.d_loss_metric.update_state(d_loss)\n",
    "        self.g_loss_metric.update_state(g_loss)\n",
    "        return {\n",
    "            \"d_loss\": self.d_loss_metric.result(),\n",
    "            \"g_loss\": self.g_loss_metric.result(),\n",
    "        }\n",
    "\n",
    "    def test_step(self, real_images):\n",
    "        \n",
    "\n",
    "    def generate(self, num_images):\n",
    "        eps = tf.random.normal(shape=(num_images, self.latent_dim))\n",
    "        return self.generator(eps, training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5655d43-4aec-460c-a75b-1b5061dd1ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "gan = GenerativeAdversarialNetwork(generator, discriminator, latent_dim=generator.latent_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46793132-3456-4bcb-a980-e9ffceac8104",
   "metadata": {},
   "outputs": [],
   "source": [
    "gan.compile(\n",
    "    g_optimizer = keras.optimizers.Adam(learning_rate=2e-4, beta_1=.5, beta_2=.9),\n",
    "    d_optimizer = keras.optimizers.Adam(learning_rate=2e-4, beta_1=.5, beta_2=.9),\n",
    "    loss_fn=keras.losses.BinaryCrossentropy(from_logits=True, label_smoothing=0.04)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047ab775-7498-4c90-b3e2-d05367d344b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(x):\n",
    "    image_size = discriminator_config[\"image_size\"]\n",
    "    x = tf.image.resize(x, (image_size, image_size))\n",
    "    return x / 255\n",
    "\n",
    "dataset = keras.preprocessing.image_dataset_from_directory(\n",
    "    \"celeba_hq\",\n",
    "    batch_size=32,\n",
    "    labels=None\n",
    ").map(preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb51454-74f7-4d15-953f-d07312958931",
   "metadata": {},
   "outputs": [],
   "source": [
    "gan.fit(dataset, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be0c785-30c8-4cb7-a280-5b59993bd8d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
